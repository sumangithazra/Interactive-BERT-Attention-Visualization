{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-pSNnWzsrBd"
      },
      "outputs": [],
      "source": [
        "!pip install bertviz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all necessary libraries and functions\n",
        "import torch\n",
        "from bertviz import head_view, model_view, neuron_view\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from bertviz.transformers_neuron_view import BertModel as NeuronViewModel\n",
        "from bertviz.transformers_neuron_view import BertTokenizer as NeuronViewTokenizer"
      ],
      "metadata": {
        "id": "S8lR9GSsxAKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load All Models and Tokenizers ---\n",
        "print(\"Loading models... This may take a moment.\")\n",
        "model_version = 'bert-base-uncased'\n",
        "model_type = 'bert'\n",
        "\n",
        "# Models for head_view and model_view\n",
        "model_hv = BertModel.from_pretrained(model_version, output_attentions=True)\n",
        "tokenizer_hv = BertTokenizer.from_pretrained(model_version)\n",
        "model_hv.eval()\n",
        "\n",
        "# Models for neuron_view (requires special wrappers)\n",
        "model_nv = NeuronViewModel.from_pretrained(model_version, output_attentions=True)\n",
        "tokenizer_nv = NeuronViewTokenizer.from_pretrained(model_version)\n",
        "print(\"Models loaded successfully.\")\n",
        "\n",
        "# --- 2. Create a Single, Reusable Visualization Function ---\n",
        "\n",
        "@torch.no_grad()\n",
        "def visualize_all_views(sentence_a, sentence_b=None, nv_layer=2, nv_head=8):\n",
        "    \"\"\"\n",
        "    Generates head, model, and neuron views for one or two sentences.\n",
        "\n",
        "    Args:\n",
        "        sentence_a (str): The first sentence.\n",
        "        sentence_b (str, optional): The second sentence. Defaults to None.\n",
        "        nv_layer (int): The layer to display in neuron_view.\n",
        "        nv_head (int): The head to display in neuron_view.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- A. Prepare inputs for head_view and model_view ---\n",
        "    if sentence_b:\n",
        "        print(\"\\nPreparing views for TWO sentences...\")\n",
        "        inputs = tokenizer_hv.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "        sentence_b_start = token_type_ids[0].tolist().index(1)\n",
        "    else:\n",
        "        print(\"\\nPreparing views for a SINGLE sentence...\")\n",
        "        inputs = tokenizer_hv.encode_plus(sentence_a, return_tensors='pt')\n",
        "        token_type_ids = None\n",
        "        sentence_b_start = None\n",
        "\n",
        "    input_ids = inputs['input_ids']\n",
        "    tokens = tokenizer_hv.convert_ids_to_tokens(input_ids[0])\n",
        "    attention = model_hv(input_ids, token_type_ids=token_type_ids)[-1]\n",
        "\n",
        "    # --- B. Display all three visualizations ---\n",
        "    print(\"\\n--- Head View ---\")\n",
        "    head_view(attention, tokens, sentence_b_start=sentence_b_start)\n",
        "\n",
        "    print(\"\\n--- Model View ---\")\n",
        "    model_view(attention, tokens, sentence_b_start=sentence_b_start)\n",
        "\n",
        "    print(f\"\\n--- Neuron View (Layer: {nv_layer}, Head: {nv_head}) ---\")\n",
        "    neuron_view.show(model_nv, model_type, tokenizer_nv, sentence_a, sentence_b, layer=nv_layer, head=nv_head)\n"
      ],
      "metadata": {
        "id": "ZFrRbdB2s2RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario 1: Analyze a single, ambiguous sentence\n",
        "single_sentence = \"The man saw a boy with a telescope\"\n",
        "visualize_all_views(sentence_a=single_sentence)"
      ],
      "metadata": {
        "id": "4u7DqcCxtZgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario 2: Analyze how context from a second sentence resolves ambiguity\n",
        "sentence_1 = \"The man saw a boy with a telescope\"\n",
        "sentence_2 = \"He adjusted the focus for a clearer view\"\n",
        "visualize_all_views(sentence_a=sentence_1, sentence_b=sentence_2, nv_layer=8, nv_head=6)"
      ],
      "metadata": {
        "id": "rgHwK9eltb_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fu-5UDL9t3Bj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}